{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85ca2cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boyanxu/opt/anaconda3/lib/python3.9/site-packages/Bio/SubsMat/__init__.py:126: BiopythonDeprecationWarning: Bio.SubsMat has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.substitution_matrices as a replacement, and contact the Biopython developers if you still need the Bio.SubsMat module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from Bio.PDB import *\n",
    "from Bio.PDB.DSSP import DSSP\n",
    "from Bio.PDB.DSSP import dssp_dict_from_pdb_file\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqUtils import seq1\n",
    "import Bio\n",
    "\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "from Bio.SubsMat import MatrixInfo as matlist\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy.linalg as linalg\n",
    "from scipy import sparse\n",
    "import scipy.signal\n",
    "from snf import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from difflib import SequenceMatcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0632322",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('FileS1.xlsx', skiprows = 9)\n",
    "pdbl = PDBList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "8a90fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets pdb structures from pdb database\n",
    "if False:\n",
    "    for code in set(df['PDB ID + chain']):\n",
    "        pdbl.retrieve_pdb_file(code[:4], file_format = 'pdb', pdir='pdb/LRRPredictor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ecf9b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1A9NA\n",
      "[19, 42, 64, 88, 113, 140]\n",
      "1H6UA\n",
      "[42, 64, 86, 108, 130, 152, 174, 196, 218]\n",
      "1IO0A\n",
      "[18, 47, 75, 103, 133]\n",
      "1JL5A\n",
      "[39, 59, 79, 99, 121, 141, 163, 183, 205, 225, 245]\n",
      "1O6VA\n",
      "[45, 67, 89, 111, 133, 155, 176, 198, 220, 242]\n",
      "1OGQA\n",
      "[51, 77, 102, 126, 150, 175, 198, 222, 245]\n",
      "1OZNA\n",
      "[12, 33, 57, 81, 106, 130, 154, 178, 202, 226, 254]\n",
      "1P9AG\n",
      "[11, 32, 56, 78, 101, 125, 149, 173, 196]\n",
      "1PGVA\n",
      "[16, 45, 73, 101, 132]\n",
      "1W8AA\n",
      "[9, 30, 55, 79, 103, 127]\n",
      "1WWLA\n",
      "[5, 28, 65, 92, 118, 146, 170, 198, 225, 250]\n",
      "1XEUA\n",
      "[42, 64, 86, 107, 129, 151, 173]\n",
      "1XKUA\n",
      "[11, 32, 56, 80, 101, 125, 151, 172, 196, 220, 243]\n",
      "1ZIWA\n",
      "[2, 23, 47, 71, 95, 119, 143, 169, 193, 220, 246]\n",
      "2ASTB\n",
      "[42, 65, 88, 113, 137, 163, 190, 217, 242]\n",
      "2BNHA\n",
      "[25, 53, 82, 110, 139, 167, 196, 224, 253]\n",
      "2CA6A\n",
      "needed to do alignment\n",
      "MARFSIEGKS\n",
      "2 ARFSIEGKS\n",
      "  |||||||||\n",
      "1 ARFSIEGKS\n",
      "  Score=43\n",
      "\n",
      "-1\n",
      "[-1, 32, 60, 94, 122, 159, 187, 216, 244, 274, 303, 332]\n",
      "2ELLA\n",
      "found too many chains: 20\n",
      "[25, 50, 72, 96, 121, 148]\n",
      "2FT3A\n",
      "[10, 31, 55, 79, 100, 124, 149, 170, 194, 218, 241]\n",
      "2ID5A\n",
      "[12, 33, 57, 81, 105, 129, 153, 177, 201, 225, 249]\n",
      "2IFGA\n",
      "[9, 32, 57, 81, 104]\n",
      "2JQDA\n",
      "found too many chains: 10\n",
      "[18, 43, 65, 89, 114, 141]\n",
      "2O6QA\n",
      "[17, 38, 62, 86, 110, 134, 158, 182, 206]\n",
      "2O6RA\n",
      "[8, 29, 53, 77, 101, 125, 153]\n",
      "2O6SA\n",
      "[8, 29, 53, 77, 101, 125, 149, 177]\n",
      "2P1MB\n",
      "[35, 58, 97, 122, 148, 176, 203, 227]\n",
      "2Q4GW\n",
      "found too many chains: 8\n",
      "[3, 28, 56, 85, 113, 133, 142, 170, 199, 227]\n",
      "2R9UA\n",
      "[13, 34, 58, 82, 106]\n",
      "2RA8A\n",
      "[4, 108, 140, 4, 194, 220, 253]\n",
      "2V70A\n",
      "[9, 30, 55, 79, 103, 127, 151]\n",
      "2V9TB\n",
      "[12, 33, 57, 81, 105, 129, 153]\n",
      "2WFHA\n",
      "[8, 29, 52, 76, 100, 124]\n",
      "2XOTA\n",
      "[13, 34, 59, 83, 107, 131, 4, 180]\n",
      "2XWTC\n",
      "[12, 30, 54, 79, 104, 129, 155, 178, 204, 225]\n",
      "2Z62A\n",
      "[8, 29, 53, 77, 101, 125, 150, 178, 201, 225]\n",
      "2Z63A\n",
      "[8, 29, 53, 77, 101, 125, 150, 179, 201, 228]\n",
      "2Z66A\n",
      "[8, 29, 53, 79, 102, 127, 151, 176, 200, 224, 249]\n",
      "2Z7XA\n",
      "[6, 27, 51, 75, 99, 124, 149, 173, 197, 224, 252]\n",
      "2Z7XB\n",
      "[1, 22, 46, 70, 91, 116, 139, 164, 188, 221, 248]\n",
      "2Z80A\n",
      "[6, 27, 51, 75, 99, 124, 149, 173, 197, 4, 246]\n",
      "2Z81A\n",
      "[6, 27, 51, 75, 99, 124, 149, 173, 197, 224, 252]\n",
      "3A79B\n",
      "[0, 21, 45, 69, 90, 115, 138, 163, 187, 218, 245, 271, 300, 322, 346, 372, 397, 419, 442, 466]\n",
      "3B2DA\n",
      "[8, 29, 53, 77, 101, 125, 149, 175, 198, 221, 250]\n",
      "3BZ5A\n",
      "[42, 64, 85, 106, 127, 148, 170, 191, 212, 233, 254]\n",
      "3CIGA\n",
      "[5, 26, 50, 74, 98, 122, 146, 172, 196, 223, 249]\n",
      "3E4GA\n",
      "[62, 86, 115, 140, 167]\n",
      "3E6JA\n",
      "[10, 31, 55, 79, 103, 126, 150]\n",
      "3G06A\n",
      "[32, 53, 73, 93, 113, 133, 153, 173, 193, 213, 233, 253]\n",
      "3G39A\n",
      "[8, 29, 53, 77, 101]\n",
      "3GOZA\n",
      "[23, 52, 81, 110, 139, 168, 197, 226, 254]\n",
      "3J0AA\n",
      "[4, 25, 49, 74, 98, 124, 149, 177, 205, 232]\n",
      "3JB9J\n",
      "[19, 40, 62, 86, 111, 138]\n",
      "3M19A\n",
      "[12, 33, 57, 81, 105, 129, 153, 177]\n",
      "3O53A\n",
      "[7, 34, 58, 80, 99, 120, 144, 169, 191, 214, 237]\n",
      "3O6NA\n",
      "[4, 34, 58, 82, 106, 130, 154, 175, 194, 215, 237]\n",
      "3OGKB\n",
      "[40, 63, 102, 128, 154, 182, 210, 233]\n",
      "3RFJA\n",
      "[39, 61, 83, 107, 131, 155, 179, 203]\n",
      "3RFSA\n",
      "[41, 63, 85, 109, 133, 157, 181, 205]\n",
      "3RG1A\n",
      "[8, 29, 53, 77, 101, 125, 149, 175, 198, 221, 250]\n",
      "3RGZA\n",
      "[44, 71, 94, 120, 145, 172, 194, 217, 241]\n",
      "3RW6A\n",
      "[106, 149, 175, 199]\n",
      "3SB4A\n",
      "[1, 26, 50, 102, 125, 147, 169, 177, 204, 4, 251]\n",
      "3T6QA\n",
      "[8, 29, 53, 77, 101, 125, 149, 175, 198, 221, 250]\n",
      "3TSRE\n",
      "[0, 25, 53, 82, 110, 139, 167, 196, 224, 253, 281, 310, 338, 367, 395, 424, 451]\n",
      "3TWID\n",
      "[9, 30, 54, 78, 102]\n",
      "3UN9A\n",
      "[31, 60, 85, 114, 142, 170, 198, 4]\n",
      "3V44A\n",
      "[5, 25, 49, 74, 98, 124, 149, 175, 207, 234]\n",
      "3VQ2A\n",
      "[7, 28, 52, 76, 100, 124, 149, 177, 200, 227]\n",
      "3WN4A\n",
      "[4, 31, 55, 80, 101, 125, 156, 177, 201]\n",
      "3WO9A\n",
      "[22, 43, 67, 91, 115, 139, 163]\n",
      "3WPEA\n",
      "[10, 35, 59, 95, 115, 139, 171, 192, 216]\n",
      "3ZYIA\n",
      "[12, 33, 57, 81, 105, 129, 154, 176, 200, 224, 248]\n",
      "3ZYJA\n",
      "[12, 33, 57, 81, 105, 129, 154, 176, 200, 224, 248]\n",
      "3ZYOA\n",
      "[4, 30, 54, 78, 102, 126, 151, 173, 197, 221, 245]\n",
      "4ARNA\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# edge cases: '2Z66A', 3JB9J, 4CP6A, 2ELLA, '2CA6A'\n",
    "\n",
    "LRR_d = {}\n",
    "\n",
    "for ii in range(df.shape[0]):\n",
    "    if ii%2:\n",
    "        code = df.iloc[ii]['PDB ID + chain']\n",
    "        if code != '2CA6A':\n",
    "            pass\n",
    "        pdb_code = code[:4]\n",
    "        chain_id = code[4]\n",
    "        entry = df.iloc[ii-1]['entry']\n",
    "        motifs = df.iloc[ii]['entry']        \n",
    "        print(code)\n",
    "\n",
    "        prefixSize = 5\n",
    "        matchingRecords = []\n",
    "        for record in SeqIO.parse(\"pdb/LRRPredictor/pdb%s.ent\"%pdb_code, \"pdb-seqres\"):                 \n",
    "            if record.annotations[\"chain\"].upper()==chain_id:\n",
    "                delta = 0\n",
    "                offset = -1\n",
    "                while delta < 10 and offset < 0:\n",
    "                    offset = record.seq[delta:].find(entry[delta:prefixSize+delta])\n",
    "                    delta += 1\n",
    "                if offset >=0:\n",
    "                    matchingRecords.append((record, offset))\n",
    "        if not matchingRecords:\n",
    "            raise Exception ('did not find chain with matching prefix')\n",
    "        elif len(matchingRecords)>1:\n",
    "            raise Exception ('found more than one matching record')\n",
    "        offset = matchingRecords[0][1]\n",
    "        chain_id_cased = matchingRecords[0][0].annotations[\"chain\"]       \n",
    "                \n",
    "        #get pdb sequence\n",
    "        parser = PDBParser()\n",
    "        structure = parser.get_structure(pdb_code, \"pdb/LRRPredictor/pdb%s.ent\"%pdb_code)        \n",
    "        chains = []\n",
    "        for model in structure:\n",
    "            for chain in model:\n",
    "                if chain.id == chain_id_cased:\n",
    "                    chains.append(chain)\n",
    "                    \n",
    "        if len(chains) == 0:\n",
    "            raise Exception ('no chains found')\n",
    "        elif len(chains) == 1:\n",
    "            chain = chains[0]\n",
    "            pdbseq = ''.join([seq1(res.get_resname()) for res in chain.get_residues()])\n",
    "        else:\n",
    "            print('found too many chains:', len(chains))\n",
    "            chain = chains[0]\n",
    "            pdbseq = ''.join([seq1(res.get_resname()) for res in chain.get_residues()])            \n",
    "        \n",
    "        #try to align motif window to pdb sequence\n",
    "\n",
    "        matrix = matlist.blosum62\n",
    "        queryRadius = 5\n",
    "        motifLocs = []\n",
    "        for jj, char in enumerate(motifs):\n",
    "            if char != '-':\n",
    "                if jj-queryRadius<0:\n",
    "                    lb = 0\n",
    "                    ub = 2*queryRadius\n",
    "                elif jj+queryRadius>len(entry):\n",
    "                    lb = len(entry)-2*queryRadius\n",
    "                    ub = len(entry)\n",
    "                else:\n",
    "                    lb = jj - queryRadius\n",
    "                    ub = jj + queryRadius\n",
    "                query = entry[lb:ub]\n",
    "                \n",
    "                motifLoc = pdbseq.find(query)+jj-lb\n",
    "                \n",
    "                if motifLoc < 0:\n",
    "                    print('needed to do alignment')\n",
    "                    print(query)\n",
    "                    try:\n",
    "                        a=pairwise2.align.localds(query, pdbseq, matrix, -1, -1, penalize_end_gaps=(False, False), one_alignment_only=True)[0]\n",
    "                        print(format_alignment(*a))\n",
    "                        # a = next(pairwise2.align.localdx(query, pdbseq, matrix, one_alignment_only=True))                        \n",
    "                        # a = next(pairwise2.align.localds(query, pdbseq, matrix, -1, -1, penalize_end_gaps=(False, False), one_alignment_only=True))                        \n",
    "                    except:\n",
    "                        print(pdbseq)\n",
    "                        raise Exception('alignment failed')\n",
    "                    if a.score <queryRadius*2:\n",
    "                        raise Exception('no alignments found')\n",
    "                    \n",
    "                    queryShift = int(format_alignment(*a).split(' ')[0])-1\n",
    "                    start = int(format_alignment(*a).split(' ')[3].split('\\n')[1])-1\n",
    "                    motifLoc = start+jj-lb-queryShift\n",
    "                    print(motifLoc)\n",
    "                motifLocs.append(motifLoc)\n",
    "\n",
    "        print(motifLocs)\n",
    "        LRR_d[code] = motifLocs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d043b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('pickles/LRRPred_validation.pickle', 'wb') as handle:\n",
    "    pickle.dump(LRR_d, handle, protocol = pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e790b61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del LRR_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8834f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bf9e1939a68d44f71c3e8d1efa56a3e75bb2bbd68ef8494dafe73f447090d051"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
